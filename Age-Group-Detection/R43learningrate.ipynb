{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimum learning rate - Fixed for Python 3.11 and TensorFlow 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 12:48:56.197058: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-23 12:48:56.205234: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-23 12:48:56.229798: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750663136.268358   18533 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750663136.283126   18533 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750663136.314918   18533 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750663136.314954   18533 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750663136.314958   18533 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750663136.314962   18533 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-23 12:48:56.325703: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import utils\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "# Use imageio.v2 to avoid deprecation warnings\n",
    "import imageio.v2 as imageio\n",
    "from PIL import Image\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "train = pd.read_csv('agedetectiontrain/train.csv')\n",
    "\n",
    "# Image resizing of test data into single numpy array\n",
    "temp = []\n",
    "for img_name in train.ID:\n",
    "    img_path = os.path.join('agedetectiontrain/Train', img_name)\n",
    "    img = imageio.imread(img_path)\n",
    "    img = np.array(Image.fromarray(img).resize((32, 32))).astype('float32')    \n",
    "    temp.append(img)\n",
    "\n",
    "train_x = np.stack(temp)\n",
    "\n",
    "# Normalizing the images\n",
    "train_x = train_x / 255.\n",
    "\n",
    "# Encoding the categorical variable to numeric\n",
    "lb = LabelEncoder()\n",
    "train_y = lb.fit_transform(train.Class)\n",
    "train_y = keras.utils.to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying all the parameters we will be using in our network\n",
    "input_num_units = (32, 32, 3)\n",
    "hidden_num_units = 500\n",
    "output_num_units = 3\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 12:49:38.115378: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Create model function for reusability\n",
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=input_num_units),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(hidden_num_units, activation='relu'),\n",
    "        keras.layers.Dense(output_num_units, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters like optimizer, loss function and evaluating metric\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified Learning Rate Finder\n",
    "class SimpleLRFinder:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.lrs = []\n",
    "        self.losses = []\n",
    "        \n",
    "    def find_lr(self, X, y, start_lr=1e-7, end_lr=10, num_it=100, beta=0.98):\n",
    "        # Save original weights\n",
    "        original_weights = self.model.get_weights()\n",
    "        \n",
    "        # Initialize\n",
    "        self.lrs = []\n",
    "        self.losses = []\n",
    "        \n",
    "        # Learning rate multiplier\n",
    "        mult = (end_lr / start_lr) ** (1/num_it)\n",
    "        lr = start_lr\n",
    "        \n",
    "        # Create a copy of the model for lr finding\n",
    "        temp_model = create_model()\n",
    "        temp_model.compile(loss='categorical_crossentropy',\n",
    "                          optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                          metrics=['accuracy'])\n",
    "        \n",
    "        # Variables for smoothing\n",
    "        avg_loss = 0\n",
    "        best_loss = 0\n",
    "        \n",
    "        # Randomly select indices for training\n",
    "        indices = np.random.choice(len(X), size=num_it * 32, replace=True)\n",
    "        \n",
    "        print(f\"Finding learning rate from {start_lr} to {end_lr}...\")\n",
    "        \n",
    "        for i in range(num_it):\n",
    "            # Get batch\n",
    "            batch_indices = indices[i*32:(i+1)*32]\n",
    "            batch_x = X[batch_indices]\n",
    "            batch_y = y[batch_indices]\n",
    "            \n",
    "            # Update learning rate\n",
    "            temp_model.optimizer.learning_rate.assign(lr)\n",
    "            \n",
    "            # Train on batch\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = temp_model(batch_x, training=True)\n",
    "                loss = temp_model.compiled_loss(batch_y, predictions)\n",
    "            \n",
    "            # Get gradients and apply\n",
    "            gradients = tape.gradient(loss, temp_model.trainable_variables)\n",
    "            temp_model.optimizer.apply_gradients(zip(gradients, temp_model.trainable_variables))\n",
    "            \n",
    "            # Convert loss to numpy\n",
    "            loss_val = float(loss.numpy())\n",
    "            \n",
    "            # Smooth the loss\n",
    "            if i == 0:\n",
    "                avg_loss = loss_val\n",
    "            else:\n",
    "                avg_loss = beta * avg_loss + (1 - beta) * loss_val\n",
    "            \n",
    "            smoothed_loss = avg_loss / (1 - beta ** (i + 1))\n",
    "            \n",
    "            # Record\n",
    "            self.lrs.append(lr)\n",
    "            self.losses.append(smoothed_loss)\n",
    "            \n",
    "            # Check if loss is exploding\n",
    "            if i > 0 and smoothed_loss > 4 * best_loss:\n",
    "                print(f\"Stopping early at iteration {i} due to loss explosion\")\n",
    "                break\n",
    "                \n",
    "            # Update best loss\n",
    "            if smoothed_loss < best_loss or i == 0:\n",
    "                best_loss = smoothed_loss\n",
    "            \n",
    "            # Update learning rate\n",
    "            lr *= mult\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(f\"Iteration {i}, LR: {self.lrs[-1]:.2e}, Loss: {smoothed_loss:.4f}\")\n",
    "        \n",
    "        # Restore original model weights\n",
    "        self.model.set_weights(original_weights)\n",
    "        print(\"Learning rate finder completed!\")\n",
    "        \n",
    "    def plot(self, skip_start=10, skip_end=5):\n",
    "        if len(self.lrs) == 0:\n",
    "            print(\"No data to plot. Run find_lr first.\")\n",
    "            return\n",
    "            \n",
    "        # Skip some points\n",
    "        lrs = self.lrs[skip_start:len(self.lrs)-skip_end] if skip_end > 0 else self.lrs[skip_start:]\n",
    "        losses = self.losses[skip_start:len(self.losses)-skip_end] if skip_end > 0 else self.losses[skip_start:]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(lrs, losses)\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('Learning Rate')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Learning Rate vs Loss')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        # Find optimal learning rate (steepest descent)\n",
    "        try:\n",
    "            gradients = np.gradient(losses)\n",
    "            min_gradient_idx = np.argmin(gradients)\n",
    "            optimal_lr = lrs[min_gradient_idx]\n",
    "            print(f\"Suggested learning rate: {optimal_lr:.2e}\")\n",
    "            return optimal_lr\n",
    "        except:\n",
    "            print(\"Could not determine optimal learning rate\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding learning rate from 1e-06 to 0.1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolf/anaconda3/envs/deepl-env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:671: UserWarning: `model.compiled_loss()` is deprecated. Instead, use `model.compute_loss(x, y, y_pred, sample_weight, training)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, LR: 1.00e-06, Loss: 48.8988\n",
      "Iteration 10, LR: 3.16e-06, Loss: 4.9462\n",
      "Iteration 20, LR: 1.00e-05, Loss: 2.8335\n",
      "Iteration 30, LR: 3.16e-05, Loss: 2.1090\n",
      "Iteration 40, LR: 1.00e-04, Loss: 1.7288\n",
      "Iteration 50, LR: 3.16e-04, Loss: 1.4999\n",
      "Iteration 60, LR: 1.00e-03, Loss: 1.3581\n",
      "Iteration 70, LR: 3.16e-03, Loss: 1.3758\n",
      "Iteration 80, LR: 1.00e-02, Loss: 1.3086\n",
      "Iteration 90, LR: 3.16e-02, Loss: 1.2321\n",
      "Learning rate finder completed!\n"
     ]
    }
   ],
   "source": [
    "# Use the learning rate finder\n",
    "lr_finder = SimpleLRFinder(model)\n",
    "lr_finder.find_lr(train_x, train_y, start_lr=1e-6, end_lr=1e-1, num_it=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested learning rate: 3.16e-06\n"
     ]
    }
   ],
   "source": [
    "# Plot the results\n",
    "optimal_lr = lr_finder.plot(skip_start=10, skip_end=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the above figure, choose appropriate learning rates:\n",
    "* base_lr = $10^{-4}$ (or use the suggested optimal learning rate divided by 10)\n",
    "* max_lr = $10^{-3}$ (or use the suggested optimal learning rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting cyclic learning rate for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified Cyclic Learning Rate Callback\n",
    "class CyclicLR(keras.callbacks.Callback):\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000, mode='triangular2'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.clr_iterations = 0\n",
    "        self.trn_iterations = 0\n",
    "        self.history = {'lr': [], 'iterations': []}\n",
    "\n",
    "    def clr(self):\n",
    "        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))\n",
    "        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)\n",
    "        \n",
    "        if self.mode == 'triangular':\n",
    "            scale_factor = 1.0\n",
    "        elif self.mode == 'triangular2':\n",
    "            scale_factor = 1 / (2.0 ** (cycle - 1))\n",
    "        else:\n",
    "            scale_factor = 1.0\n",
    "            \n",
    "        return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x)) * scale_factor\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.model.optimizer.learning_rate.assign(self.base_lr)\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "        \n",
    "        # Record current learning rate\n",
    "        current_lr = float(self.model.optimizer.learning_rate.numpy())\n",
    "        self.history['lr'].append(current_lr)\n",
    "        self.history['iterations'].append(self.trn_iterations)\n",
    "        \n",
    "        # Set new learning rate\n",
    "        new_lr = self.clr()\n",
    "        self.model.optimizer.learning_rate.assign(new_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh model for training\n",
    "model = create_model()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Set up callbacks\n",
    "cb_triangular = CyclicLR(base_lr=0.0001, max_lr=0.001, step_size=2000, mode='triangular2')\n",
    "cb_save = keras.callbacks.TensorBoard(log_dir='learning_rate', write_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 12:49:48.782222: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 195674112 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.5433 - loss: 0.9709 - val_accuracy: 0.6022 - val_loss: 0.8637\n",
      "Epoch 2/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.6063 - loss: 0.8541 - val_accuracy: 0.6193 - val_loss: 0.8302\n",
      "Epoch 3/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6177 - loss: 0.8325 - val_accuracy: 0.6296 - val_loss: 0.8189\n",
      "Epoch 4/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6218 - loss: 0.8179 - val_accuracy: 0.6369 - val_loss: 0.7985\n",
      "Epoch 5/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6349 - loss: 0.7968 - val_accuracy: 0.5768 - val_loss: 0.8897\n",
      "Epoch 6/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6213 - loss: 0.8141 - val_accuracy: 0.6524 - val_loss: 0.7861\n",
      "Epoch 7/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.6461 - loss: 0.7884 - val_accuracy: 0.6017 - val_loss: 0.8442\n",
      "Epoch 8/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.6433 - loss: 0.7883 - val_accuracy: 0.6527 - val_loss: 0.7727\n",
      "Epoch 9/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 0.6552 - loss: 0.7713 - val_accuracy: 0.6205 - val_loss: 0.8249\n",
      "Epoch 10/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.6492 - loss: 0.7733 - val_accuracy: 0.6467 - val_loss: 0.7877\n",
      "Epoch 11/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6600 - loss: 0.7612 - val_accuracy: 0.6032 - val_loss: 0.8369\n",
      "Epoch 12/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 0.6420 - loss: 0.7871 - val_accuracy: 0.6080 - val_loss: 0.8476\n",
      "Epoch 13/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.6553 - loss: 0.7586 - val_accuracy: 0.5781 - val_loss: 0.8822\n",
      "Epoch 14/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.6585 - loss: 0.7660 - val_accuracy: 0.6705 - val_loss: 0.7547\n",
      "Epoch 15/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6835 - loss: 0.7290 - val_accuracy: 0.5947 - val_loss: 0.8841\n",
      "Epoch 16/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.6577 - loss: 0.7556 - val_accuracy: 0.6602 - val_loss: 0.7814\n",
      "Epoch 17/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.6803 - loss: 0.7327 - val_accuracy: 0.6384 - val_loss: 0.7830\n",
      "Epoch 18/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - accuracy: 0.6789 - loss: 0.7165 - val_accuracy: 0.6735 - val_loss: 0.7469\n",
      "Epoch 19/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6806 - loss: 0.7216 - val_accuracy: 0.6783 - val_loss: 0.7306\n",
      "Epoch 20/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.6895 - loss: 0.7123 - val_accuracy: 0.6773 - val_loss: 0.7479\n",
      "Epoch 21/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 0.6652 - loss: 0.7491 - val_accuracy: 0.6273 - val_loss: 0.8022\n",
      "Epoch 22/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.6841 - loss: 0.7126 - val_accuracy: 0.6866 - val_loss: 0.7092\n",
      "Epoch 23/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6957 - loss: 0.6927 - val_accuracy: 0.6637 - val_loss: 0.7693\n",
      "Epoch 24/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.6938 - loss: 0.7039 - val_accuracy: 0.6888 - val_loss: 0.7183\n",
      "Epoch 25/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.6988 - loss: 0.6866 - val_accuracy: 0.6843 - val_loss: 0.7283\n",
      "Epoch 26/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 0.7081 - loss: 0.6771 - val_accuracy: 0.6816 - val_loss: 0.7306\n",
      "Epoch 27/100\n",
      "\u001b[1m15/32\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.6947 - loss: 0.7018"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting model training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcb_triangular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcb_save\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mModel training completed successfully!\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/deepl-env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/deepl-env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/deepl-env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/deepl-env/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/deepl-env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/deepl-env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/deepl-env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/deepl-env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/deepl-env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/deepl-env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/deepl-env/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/deepl-env/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Starting model training...\")\n",
    "history = model.fit(train_x, train_y, \n",
    "                   batch_size=batch_size, \n",
    "                   epochs=epochs, \n",
    "                   validation_split=0.2, \n",
    "                   callbacks=[cb_triangular, cb_save], \n",
    "                   verbose=1)\n",
    "print('Model training completed successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cyclic learning rate\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot learning rate schedule\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(cb_triangular.history['iterations'], cb_triangular.history['lr'])\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title(\"CLR - 'triangular2' Policy\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot training loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot training accuracy\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot learning rate vs loss\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(cb_triangular.history['lr'][:len(history.history['loss'])], history.history['loss'])\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Learning Rate vs Training Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
