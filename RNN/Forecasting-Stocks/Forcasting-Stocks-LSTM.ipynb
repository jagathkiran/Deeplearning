{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forcasting Stocks using RNN (LSTM)\n",
    "\n",
    "### To start with the implementation of a basic LSTM on time series forecasting, we import the necessary libraries and load the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = pd.read_csv('INFY20002008.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we use subset only the Date and Average Price attributes out of which we are going to focus upon Average Price and Date is left just for labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting only Date and Average Price columns\n",
    "data = data[['Date', 'Average Price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us now proceed with scaling the values and splitting the data set in train and test portions. Remember don't shuffle the dataset while splitting. It should be split following a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the values in the range of 0 to 1\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "scaled_price = scaler.fit_transform(data.loc[:, 'Average Price'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset in the ratio of 75:25 for training and test\n",
    "train_size = int(data.shape[0] * 0.75)\n",
    "train, test = scaled_price[0:train_size, :], scaled_price[train_size:data.shape[0], :]\n",
    "print(\"Number of entries (training set, test set): \" + str((len(train), len(test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we need to construct a data set from the array of Average Price values along with defining a window size. \n",
    "#### Window is used to define how many values need to be taken while forecasting the new value. By default, in the function, we set the window size as 1, however, while constructing the data set, we set the window size to 3. You can change it and observe the corresponding effect on the forecasted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(scaled_price, window_size=1):\n",
    "    data_X, data_Y = [], []\n",
    "    for i in range(len(scaled_price) - window_size - 1):\n",
    "        a = scaled_price[i:(i + window_size), 0]\n",
    "        data_X.append(a)\n",
    "        data_Y.append(scaled_price[i + window_size, 0])\n",
    "    return(np.array(data_X), np.array(data_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we call the function and reset the dataset to make it fit for Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test and training sets for one-step-ahead regression.\n",
    "window_size = 3\n",
    "train_X, train_Y = create_dataset(train, window_size)\n",
    "test_X, test_Y = create_dataset(test, window_size)\n",
    "print(\"Original training data shape:\")\n",
    "print(train_X.shape)\n",
    "\n",
    "# Reshape the input data into appropriate form for Keras.\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(\"New training data shape:\")\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we design our LSTM network with four blocks and just one layer using the MSE as loss function with three epochs.\n",
    "\n",
    "\n",
    "The LSTM architecture here consists of:  \n",
    "\n",
    "* One input layer.  \n",
    "* One LSTM layer of 4 blocks.  \n",
    "* One Dense layer to produce a single output.  \n",
    "* MSE as loss function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape = (1, window_size)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss = \"mean_squared_error\", optimizer = \"adam\")\n",
    "\n",
    "# Training the model\n",
    "model.fit(train_X, train_Y, epochs=3, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting and visualization\n",
    "#### Let us now check the MSE in train and test data and perform the corresponding visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_score(model, X, Y):\n",
    "    # Make predictions on the original scale of the data.\n",
    "    pred = scaler.inverse_transform(model.predict(X))\n",
    "    # Prepare Y data to also be on the original scale for interpretability.\n",
    "    orig_data = scaler.inverse_transform([Y])\n",
    "    # Calculate RMSE.\n",
    "    score = np.sqrt(mean_squared_error(orig_data[0], pred[:, 0]))\n",
    "    return(score, pred)\n",
    "\n",
    "rmse_train, train_predict = predict_and_score(model, train_X, train_Y)\n",
    "rmse_test, test_predict = predict_and_score(model, test_X, test_Y)\n",
    "\n",
    "print(\"Training data score: %.2f RMSE\" % rmse_train)\n",
    "print(\"Test data score: %.2f RMSE\" % rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with training predictions.\n",
    "train_predict_plot = np.empty_like(scaled_price)\n",
    "train_predict_plot[:, :] = np.nan\n",
    "train_predict_plot[window_size:len(train_predict) + window_size, :] = train_predict\n",
    "\n",
    "# Add test predictions.\n",
    "test_predict_plot = np.empty_like(scaled_price)\n",
    "test_predict_plot[:, :] = np.nan\n",
    "test_predict_plot[len(train_predict) + (window_size * 2) + 1:len(scaled_price) - 1, :] = test_predict\n",
    "\n",
    "# Create the plot.\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.plot(scaler.inverse_transform(scaled_price), label = \"True value\")\n",
    "plt.plot(train_predict_plot, label = \"Training set prediction\")\n",
    "plt.plot(test_predict_plot, label = \"Test set prediction\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Average Price\")\n",
    "plt.title(\"Comparison true vs. predicted training / test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
