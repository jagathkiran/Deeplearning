{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c39c9899",
   "metadata": {},
   "source": [
    "#### To predict the income of a US population using Census data set.\n",
    "#### 1. Setup for Wide and Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57f4331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATA=$(pwd)/data/adult.data.csv\n",
    "# EVAL_DATA=$(pwd)/data/adult.test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29f56dc",
   "metadata": {},
   "source": [
    "#### 2. Define base feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8497b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "age = tf.feature_column.numeric_column('age')\n",
    "education_num = tf.feature_column.numeric_column('education_num')\n",
    "capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
    "capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
    "hours_per_week = tf.feature_column.numeric_column('hours_per_week')\n",
    "education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "'education', [\n",
    "'Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college',\n",
    "'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school',\n",
    "'5th-6th', '10th', '1st-4th', 'Preschool', '12th'])\n",
    "marital_status = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "'marital_status', [\n",
    "'Married-civ-spouse', 'Divorced', 'Married-spouse-absent',\n",
    "'Never-married', 'Separated', 'Married-AF-spouse', 'Widowed'])\n",
    "relationship = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "'relationship', [\n",
    "'Husband', 'Not-in-family', 'Wife', 'Own-child', 'Unmarried',\n",
    "'Other-relative'])\n",
    "workclass = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "'workclass', [\n",
    "'Self-emp-not-inc', 'Private', 'State-gov', 'Federal-gov',\n",
    "'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'])\n",
    "# hashing:\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "'occupation', hash_bucket_size=1000)\n",
    "# Transforming.\n",
    "age_buckets = tf.feature_column.bucketized_column(\n",
    "age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0322210c",
   "metadata": {},
   "source": [
    "#### 3. Deep model: neural network with embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ea58cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_columns = [\n",
    "    age,\n",
    "    education_num,\n",
    "    capital_gain,\n",
    "    capital_loss,\n",
    "    hours_per_week,    tf.feature_column.indicator_column(workclass),\n",
    "    tf.feature_column.indicator_column(education),\n",
    "    tf.feature_column.indicator_column(marital_status),\n",
    "    tf.feature_column.indicator_column(relationship),\n",
    "    # To show an example of embedding\n",
    "    tf.feature_column.embedding_column(occupation, dimension=8),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40859f4",
   "metadata": {},
   "source": [
    "#### 4. Combining wide and deep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c6885",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.estimator.DNNLinearCombinedClassifier(\n",
    "    model_dir='/tmp/census_model',\n",
    "    linear_feature_columns=base_columns + crossed_columns,\n",
    "    dnn_feature_columns=deep_columns,\n",
    "    dnn_hidden_units=[100, 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f76739",
   "metadata": {},
   "source": [
    "#### 5. Training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c73c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model every `FLAGS.epochs_per_eval` epochs.\n",
    "for n in range(FLAGS.train_epochs // FLAGS.epochs_per_eval):\n",
    "  model.train(input_fn=lambda: input_fn(FLAGS.train_data, FLAGS.epochs_per_eval, True, FLAGS.batch_size))\n",
    "  results = model.evaluate(input_fn=lambda: input_fn( FLAGS.test_data, 1, False, FLAGS.batch_size))\n",
    "  # Display evaluation metrics\n",
    "  print('Results at epoch', (n + 1) * FLAGS.epochs_per_eval)\n",
    "  print('-' * 30)\n",
    "  for key in sorted(results):\n",
    "    print('%s: %s' % (key, results[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
