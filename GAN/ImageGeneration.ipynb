{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676d8bc7",
   "metadata": {},
   "source": [
    "### New image generation using CIFAR data Set\n",
    "#### Step 1: Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64dbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import keras \n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout \n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D \n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import UpSampling2D, Conv2D \n",
    "from keras.models import Sequential, Model \n",
    "from keras.optimizers import Adam,SGD "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08e61c3",
   "metadata": {},
   "source": [
    "#### Step 2: Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb128090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the CIFAR10 data \n",
    "(X, y), (_, _) = keras.datasets.cifar10.load_data() \n",
    "  \n",
    "#Selecting a single class images \n",
    "#The number was randomly chosen and any number \n",
    "#between 1 to 10 can be chosen \n",
    "X = X[y.flatten() == 8] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cb32ff",
   "metadata": {},
   "source": [
    "#### Step 3: Defining parameters to be used in later processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651a93d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Input shape \n",
    "image_shape = (32, 32, 3) \n",
    "          \n",
    "latent_dimensions = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cb9353",
   "metadata": {},
   "source": [
    "#### Step 4: Defining a utility function to build the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(): \n",
    "  \n",
    "        model = Sequential() \n",
    "  \n",
    "        #Building the input layer \n",
    "        model.add(Dense(128 * 8 * 8, activation=\"relu\", \n",
    "                        input_dim=latent_dimensions)) \n",
    "        model.add(Reshape((8, 8, 128))) \n",
    "          \n",
    "        model.add(UpSampling2D()) \n",
    "          \n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\")) \n",
    "        model.add(BatchNormalization(momentum=0.78)) \n",
    "        model.add(Activation(\"relu\")) \n",
    "          \n",
    "        model.add(UpSampling2D()) \n",
    "          \n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\")) \n",
    "        model.add(BatchNormalization(momentum=0.78)) \n",
    "        model.add(Activation(\"relu\")) \n",
    "          \n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\")) \n",
    "        model.add(Activation(\"tanh\")) \n",
    "  \n",
    "  \n",
    "        #Generating the output image \n",
    "        noise = Input(shape=(latent_dimensions,)) \n",
    "        image = model(noise) \n",
    "  \n",
    "        return Model(noise, image) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa72e2",
   "metadata": {},
   "source": [
    "#### Step 5: Defining a utility function to build the Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d888eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(): \n",
    "  \n",
    "        #Building the convolutional layers \n",
    "        #to classify whether an image is real or fake \n",
    "        model = Sequential() \n",
    "  \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, \n",
    "                         input_shape=image_shape, padding=\"same\")) \n",
    "        model.add(LeakyReLU(alpha=0.2)) \n",
    "        model.add(Dropout(0.25)) \n",
    "          \n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\")) \n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1)))) \n",
    "        model.add(BatchNormalization(momentum=0.82)) \n",
    "        model.add(LeakyReLU(alpha=0.25)) \n",
    "        model.add(Dropout(0.25)) \n",
    "          \n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\")) \n",
    "        model.add(BatchNormalization(momentum=0.82)) \n",
    "        model.add(LeakyReLU(alpha=0.2)) \n",
    "        model.add(Dropout(0.25)) \n",
    "          \n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\")) \n",
    "        model.add(BatchNormalization(momentum=0.8)) \n",
    "        model.add(LeakyReLU(alpha=0.25)) \n",
    "        model.add(Dropout(0.25)) \n",
    "          \n",
    "        #Building the output layer \n",
    "        model.add(Flatten()) \n",
    "        model.add(Dense(1, activation='sigmoid')) \n",
    "  \n",
    "        image = Input(shape=image_shape) \n",
    "        validity = model(image) \n",
    "  \n",
    "        return Model(image, validity) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5606954c",
   "metadata": {},
   "source": [
    "#### Step 6: Defining a utility function to display the generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6060146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(): \n",
    "        r, c = 4,4\n",
    "        noise = np.random.normal(0, 1, (r * c,latent_dimensions)) \n",
    "        generated_images = generator.predict(noise) \n",
    "  \n",
    "        #Scaling the generated images \n",
    "        generated_images = 0.5 * generated_images + 0.5\n",
    "  \n",
    "        fig, axs = plt.subplots(r, c) \n",
    "        count = 0\n",
    "        for i in range(r): \n",
    "            for j in range(c): \n",
    "                axs[i,j].imshow(generated_images[count, :,:,]) \n",
    "                axs[i,j].axis('off') \n",
    "                count += 1\n",
    "        plt.show() \n",
    "        plt.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbce2fc",
   "metadata": {},
   "source": [
    "#### Step 7: Building the Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330a6b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building and compiling the discriminator \n",
    "discriminator = build_discriminator() \n",
    "discriminator.compile(loss='binary_crossentropy', \n",
    "                      optimizer=Adam(0.0002,0.5), \n",
    "                    metrics=['accuracy']) \n",
    "  \n",
    "#Making the Discriminator untrainable \n",
    "#so that the generator can learn from fixed gradient \n",
    "discriminator.trainable = False\n",
    "  \n",
    "# Building the generator \n",
    "generator = build_generator() \n",
    "  \n",
    "#Defining the input for the generator \n",
    "#and generating the images \n",
    "z = Input(shape=(latent_dimensions,)) \n",
    "image = generator(z) \n",
    "  \n",
    "  \n",
    "#Checking the validity of the generated image \n",
    "valid = discriminator(image) \n",
    "  \n",
    "#Defining the combined model of the Generator and the Discriminator \n",
    "combined_network = Model(z, valid) \n",
    "combined_network.compile(loss='binary_crossentropy', \n",
    "                         optimizer=Adam(0.0002,0.5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea5039",
   "metadata": {},
   "source": [
    "#### Step 8: Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d2d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=15000\n",
    "batch_size=32\n",
    "display_interval=2500\n",
    "losses=[] \n",
    "  \n",
    "#Normalizing the input \n",
    "X = (X / 127.5) - 1.\n",
    "          \n",
    "  \n",
    "#Defining the Adversarial ground truths \n",
    "valid = np.ones((batch_size, 1)) \n",
    "  \n",
    "#Adding some noise  \n",
    "valid += 0.05 * np.random.random(valid.shape) \n",
    "fake = np.zeros((batch_size, 1)) \n",
    "fake += 0.05 * np.random.random(fake.shape) \n",
    "  \n",
    "for epoch in range(num_epochs): \n",
    "              \n",
    "            #Training the Discriminator \n",
    "              \n",
    "            #Sampling a random half of images \n",
    "            index = np.random.randint(0, X.shape[0], batch_size) \n",
    "            images = X[index] \n",
    "  \n",
    "            #Sampling noise and generating a batch of new images \n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dimensions)) \n",
    "            generated_images = generator.predict(noise) \n",
    "              \n",
    "  \n",
    "            #Training the discriminator to detect more accurately \n",
    "            #whether a generated image is real or fake \n",
    "            discm_loss_real = discriminator.train_on_batch(images, valid) \n",
    "            discm_loss_fake = discriminator.train_on_batch(generated_images, fake) \n",
    "            discm_loss = 0.5 * np.add(discm_loss_real, discm_loss_fake) \n",
    "              \n",
    "            #Training the Generator \n",
    "  \n",
    "            #Training the generator to generate images \n",
    "            #which pass the authenticity test \n",
    "            genr_loss = combined_network.train_on_batch(noise, valid) \n",
    "              \n",
    "            #Tracking the progress                 \n",
    "            if epoch % display_interval == 0: \n",
    "                 display_images() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
